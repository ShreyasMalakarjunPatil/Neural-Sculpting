{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms1 = transforms.Compose([transforms.Grayscale(), transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "train_dataset = datasets.ImageFolder('./multimnist/' + 'train/', transform=transforms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1000,\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "t = list(map(list, itertools.product([0, 1], repeat=3)))\n",
    "\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "    #print(train_dataset.classes[target[0]][0], train_dataset.classes[target[0]][1])\n",
    "    #print(data.size())\n",
    "\n",
    "    #if int(train_dataset.classes[target[0]][0]) < 8 and int(train_dataset.classes[target[0]][1]) < 8:\n",
    "    for i in range(800):\n",
    "        X_train.append(data[i])\n",
    "        y = np.zeros(20)\n",
    "        y[int(train_dataset.classes[target[0]][0])] = 1\n",
    "        y[int(train_dataset.classes[target[0]][1])+10] = 1\n",
    "        Y_train.append(torch.tensor(y))\n",
    "    print(y)\n",
    "\n",
    "    for i in range(800,1000):\n",
    "        X_test.append(data[i])\n",
    "        y = np.zeros(20)\n",
    "        y[int(train_dataset.classes[target[0]][0])] = 1\n",
    "        y[int(train_dataset.classes[target[0]][1])+10] = 1\n",
    "        Y_test.append(torch.tensor(y))\n",
    "    print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "data = []\n",
    "data.append(torch.stack(X_train))\n",
    "data.append(torch.stack(Y_train))\n",
    "\n",
    "modularity = [1568,2,20]\n",
    "\n",
    "with open('mnist'+str(modularity)+'train.pkl', \"wb\") as fout1:\n",
    "    pkl.dump(data, fout1, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "data = []\n",
    "data.append(torch.stack(X_test))\n",
    "data.append(torch.stack(Y_test))\n",
    "\n",
    "modularity = [1568,2,20]\n",
    "\n",
    "with open('mnist'+str(modularity)+'test.pkl', \"wb\") as fout1:\n",
    "    pkl.dump(data, fout1, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms1 = transforms.Compose([transforms.Grayscale(), transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "train_dataset = datasets.ImageFolder('./multimnist/' + 'train/', transform=transforms1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1000,\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "t = list(map(list, itertools.product([0, 1], repeat=3)))\n",
    "\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "    print(train_dataset.classes[target[0]][0], train_dataset.classes[target[0]][1])\n",
    "    #print(data.size())\n",
    "\n",
    "    if int(train_dataset.classes[target[0]][0]) < 8 and int(train_dataset.classes[target[0]][1]) < 8:\n",
    "        for i in range(800):\n",
    "            X_train.append(data[i])\n",
    "            a = int(train_dataset.classes[target[0]][0])\n",
    "            b = int(train_dataset.classes[target[0]][1])\n",
    "            c1 = (a^b)\n",
    "            y = t[c1]\n",
    "            Y_train.append(torch.tensor(y))\n",
    "        print(a,b,(a^b),c1)\n",
    "\n",
    "        for i in range(800,1000):\n",
    "            X_test.append(data[i])\n",
    "            a = int(train_dataset.classes[target[0]][0])\n",
    "            b = int(train_dataset.classes[target[0]][1])\n",
    "            c1 = (a^b)\n",
    "            y = t[c1]\n",
    "            Y_test.append(torch.tensor(y))\n",
    "        #print(a,b,c1,c2,c3,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "data = []\n",
    "data.append(torch.stack(X_train))\n",
    "data.append(torch.stack(Y_train))\n",
    "\n",
    "modularity = [1568,2,3,3]\n",
    "\n",
    "with open('mnist'+str(modularity)+'train.pkl', \"wb\") as fout1:\n",
    "    pkl.dump(data, fout1, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "data = []\n",
    "data.append(torch.stack(X_test))\n",
    "data.append(torch.stack(Y_test))\n",
    "\n",
    "modularity = [1568,2,3,3]\n",
    "\n",
    "with open('mnist'+str(modularity)+'test.pkl', \"wb\") as fout1:\n",
    "    pkl.dump(data, fout1, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.Shreyas_Research': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3098a33fd5442c86bf50ee2083b70f556d093e73c30f873e28acad71b6736f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
